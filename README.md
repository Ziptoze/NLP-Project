
# Text2Image & Image2Image Generation Server

This project implements a complete server-client pipeline for **Text-to-Image** and **Image-to-Image** generation using Stable Diffusion. It includes:

- A **gRPC-based backend server** for generating images
- A **Streamlit frontend** for interaction
- Full support for both `text2image` and `img2img` generation modes
- Resource usage tracking and visualization (CPU/GPU/Memory)

---

## ğŸ§  Features

- ğŸ”  **Text2Image**: Enter a text prompt to generate a new image
- ğŸ–¼ï¸ **Image2Image**: Provide a reference image and modify it with a prompt
- âš¡ gRPC backend optimized for performance
- ğŸ“Š Resource usage tracking and live plots
- ğŸ–¥ï¸ Web interface using **Streamlit**

---

## ğŸ–‹ï¸ Functionalities
- ğŸ”¡ Text2Image
Generate images from text prompts using Stable Diffusion's Realistic Vision v5.1 model

Adjustable parameters: guidance scale, seed, steps, etc.

- ğŸ–¼ï¸ Image2Image
Modify images with prompt guidance using img2img pipeline of Stable Diffusion's Realistic Vision v5.1 model.

Tune strength, noise level, etc.

- ğŸ¤ Speech2Text
Upload or record audio

Transcribe to text using Whisper model from OpenAI

- ğŸŒ Image Translation
Translate multilingual text in images using Seamless M4T

## ğŸ”§ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/Ziptoze/NLP-Project
cd NLP-Project
```

### 2. Create and Activate a Virtual Environment

If no virtual environment is present, create one:

```bash
python -m venv venv
```

Activate it:

```bash
# Windows
.env\Scriptsctivate

# macOS/Linux
source venv/bin/activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Compile gRPC Protobuf File

```bash
python -m grpc_tools.protoc -I app --python_out=app --grpc_python_out=app app/text2image.proto
```

---

## ğŸš€ Running the Project

### ğŸ§  Backend (gRPC Server)

```bash
python app/server.py
```

This launches the server and waits for incoming image generation requests.

### ğŸ–¼ï¸ Frontend (Streamlit App)

```bash
streamlit run app/streamlit_app.py
```

This launches a web UI to send requests and view results.

---


### ğŸ”¡ Text2Image

- Prompt-based generation
- Audio prompt also available
- Optional parameters like `guidance_scale`, `steps`, `seed`, etc.
- Implemented in `server.py` and triggered from `streamlit_app.py`

### ğŸ–¼ï¸ Image2Image

- Upload a reference image
- Modify it using a prompt
- Adjust strength, noise, and other parameters
- Uses same gRPC protocol as `text2image`

---

## ğŸ“ˆ Resource Usage and Performance Tracking

The backend measures and logs:

- CPU Usage
- GPU Usage (if available via `torch.cuda`)
- RAM usage (via `psutil`)
- Time taken for generation

You can optionally visualize these using `matplotlib` or Streamlit built-in charts.

> Tip: Add plots in `streamlit_app.py` to display performance over time.

---

## ğŸ§ª Example Commands

```bash
# Activate environment
.env\Scriptsctivate

# Install dependencies
pip install -r requirements.txt

# Compile protobuf
python -m grpc_tools.protoc -I app --python_out=app --grpc_python_out=app app/text2image.proto

# Run server
python app/server.py

# Run frontend
streamlit run app/streamlit_app.py
```

---

## ğŸ“‚ Project Structure

```
text2img-grpc-server/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ text2image.proto          # gRPC definition
â”‚   â”œâ”€â”€ server.py                 # Backend server logic
â”‚   â”œâ”€â”€ streamlit_app.py          # Streamlit UI
â”‚   â”œâ”€â”€ model_loader.py           # Model loading code
â”‚   â”œâ”€â”€ utils.py                  # Utility functions
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ venv/ (created after setup)
```

---

## ğŸ› ï¸ Requirements

- Python 3.9+
- Streamlit
- torch
- torchvision
- diffusers
- transformers
- grpcio
- grpcio-tools
- Pillow
- psutil
- matplotlib (optional for plots)

> Full list in `requirements.txt`

---

## ğŸ“Œ Notes

- Make sure to have internet access on the first run to download model weights
- You can adjust model checkpoint in `model_loader.py`
- Works on both CPU and GPU (GPU highly recommended for performance)

---

## ğŸ“¬ Contact

For bugs, issues, or suggestions, open an issue or email `your.email@example.com`.

---

## ğŸ–¼ï¸ Preview
 
*For preview: Check out the Outputs folder*

---
